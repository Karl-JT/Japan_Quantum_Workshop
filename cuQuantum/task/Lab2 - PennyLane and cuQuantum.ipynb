{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc504da2-213d-4305-9a64-931045c6887d",
   "metadata": {},
   "source": [
    "# Lightning.gpu: cuQuantum-Accelerated Quantum Machine Learning Simulations in Pennylane"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198b9c3c-a0a0-4c63-be6b-6973b3fe962e",
   "metadata": {},
   "source": [
    "In this tutorial, we'll see how to use lightning.gpu, which is a cuQuantum-accelerated state vector simulator available in Xanadu's Pennylane framework. Pennylane is especially well-suited to quantum machine learning applications.  \n",
    "\n",
    "Quantum computers have the potential to one day dramatically accelerate some machine learning workloads. For now, quantum machine learning is a highly-active research area. Due to the frequent need for long training, quantum machine learning circuits tend to be some of the most difficult and compute-intensive, and can benefit dramatically from GPU acceleration.\n",
    "\n",
    "The Pennylane page contains a great deal of information and tutorials, and is a great place to start learning more about quantum machine learning: https://pennylane.ai/ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d269653-4d0d-4977-9da7-4540a08d6148",
   "metadata": {},
   "source": [
    "In this tutorial, we'll first benchmark the cuQuantum GPU simulator against the lightning.qubit fast CPU simulator on a simple example circuit to get a sense of the cuQuantum speedup for QML workloads. Then we'll show how to implement a quantum variational classifier using lightning.gpu. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89857f8-ca6f-465a-b47c-115aac388196",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c46c0b2-f61e-426f-89ca-56231a76be49",
   "metadata": {},
   "source": [
    "We'll define two devices with 24 qubits, one using lightning.qubit and the other using lightning.gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faeb57d8-3e2b-4d9b-ada3-0da9ccaf5d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "from pennylane.optimize import NesterovMomentumOptimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e769ba-1530-4bc1-b5d1-5da0f290ae61",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_device = qml.device(\"lightning.qubit\", wires=24)\n",
    "cuquantum_device = qml.device(\"lightning.gpu\", wires=24)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca55e91-c310-493f-a0c3-8401a3227440",
   "metadata": {},
   "source": [
    "Now we'll create a qnode, which defines a quantum object in Pennylane. We'll start by defining a qnode with the lightning.qubit simulator device. For the actual circuit we'll use a single StronglyEntanglingLayer, followed by an expectation value on Pauli Z for each qubit. This is a very simple circuit but represents fundamental building blocks of a quantum machine learning algorithm. You can read more about the StronglyEntanglingLayer function here: https://pennylane.readthedocs.io/en/latest/code/api/pennylane.StronglyEntanglingLayers.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a66248b-3b4b-4aac-86e0-179a536d5c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "@qml.qnode(cpu_device, diff_method=\"adjoint\")\n",
    "def circuit(parameters):\n",
    "    qml.StronglyEntanglingLayers(weights=parameters, wires=range(24))\n",
    "    return qml.expval(qml.PauliZ(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61ed519-de6f-4045-9ab3-500fdb6648e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = qml.StronglyEntanglingLayers.shape(n_layers=2, n_wires=24)\n",
    "weights = qml.numpy.random.random(size=shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683e7e35-35f7-48ac-b13b-0874434f132e",
   "metadata": {},
   "source": [
    "## CPU Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52048f95-fbd4-4001-b459-937943a5c2cd",
   "metadata": {},
   "source": [
    "Now we'll simulate the circuit and measure the execution time. Even though this circuit is simple, the simulation is compute-intensive and this cell will take about 1-2 minutes to execute on the CPU. While it is running, you can read about the recent integration of lightning.gpu as an embedded simulator in Amazon Braket here: https://aws.amazon.com/blogs/quantum-computing/using-embedded-simulators-in-amazon-braket-hybrid-jobs/. By combining the lightning.gpu acceleration with parallelization over multiple nodes, users can achieve in the neighborhood of a 900x speedup on QML workloads, at 3.5x less cost than running the same job on a CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572ba180-3ee6-49ee-ad03-19d84e278323",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time jac = qml.jacobian(circuit)(weights)\n",
    "f\"device={cpu_device.short_name}, qubits={24}, trainable_params={len(circuit.tape.trainable_params)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e12a12-a617-4f6d-adde-65c78632c38e",
   "metadata": {},
   "source": [
    "## GPU Simulation with cuQuantum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1132ca-645d-4236-af41-c7d33aa62ddf",
   "metadata": {},
   "source": [
    "Now, let's run the exact same experiment, but using the cuQuantum device with lightning.gpu. You should see a >5x speedup just from switching the simulator. Generally this speedup will be even more dramatic as the size of the device or the depth of the circuit is increased. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc704059-3cf6-4c52-872e-6e26e201fac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@qml.qnode(cuquantum_device, diff_method=\"adjoint\")\n",
    "def circuit(parameters):\n",
    "    qml.StronglyEntanglingLayers(weights=parameters, wires=range(24))\n",
    "    return qml.expval(qml.PauliZ(0))\n",
    "\n",
    "%time jac = qml.jacobian(circuit)(weights)\n",
    "f\"device={cuquantum_device.short_name}, qubits={24}, trainable_params={len(circuit.tape.trainable_params)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796a32e3-d8b0-4dcc-a1b8-727d5e9c462b",
   "metadata": {},
   "source": [
    "## Implementing a Variational Classifier with lightning.gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115d8947-f54b-48ec-90cf-debb7c592643",
   "metadata": {},
   "source": [
    "Now let's use lightning.gpu to solve a real problem, implementing a variational quantum classifier - a quantum circuit that can be trained from labelled data to classify new data samples.\n",
    "\n",
    "We will show that the variational quantum classifier can reproduce the parity function. This optimization example demonstrates how to encode binary inputs into the initial state of the variational circuit, which is simply a computational basis state.\n",
    "\n",
    "This part of the tutorial follows the variational classifier tutorial which was developed by the Xanadu team and is available on the Pennylane site: https://pennylane.ai/qml/demos/tutorial_variational_classifier.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfe2714-e8d3-420f-a70b-b4060adfe123",
   "metadata": {},
   "source": [
    "For simplicity, we'll create a new quantum device with 4 qubits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f36e1a-7282-4818-ae2b-2197669d396c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = qml.device(\"lightning.gpu\", wires=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d8dbc6-e7f1-46bf-b8b4-369a11c89ff9",
   "metadata": {},
   "source": [
    "Variational classifiers usually define a “layer” or “block”, which is an elementary circuit architecture that gets repeated to build the variational circuit.\n",
    "\n",
    "Our circuit layer consists of an arbitrary rotation on every qubit, as well as CNOTs that entangle each qubit with its neighbor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a28a091-a549-4c67-a5ae-4d8025a5da99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer(W):\n",
    "\n",
    "    qml.Rot(W[0, 0], W[0, 1], W[0, 2], wires=0)\n",
    "    qml.Rot(W[1, 0], W[1, 1], W[1, 2], wires=1)\n",
    "    qml.Rot(W[2, 0], W[2, 1], W[2, 2], wires=2)\n",
    "    qml.Rot(W[3, 0], W[3, 1], W[3, 2], wires=3)\n",
    "\n",
    "    qml.CNOT(wires=[0, 1])\n",
    "    qml.CNOT(wires=[1, 2])\n",
    "    qml.CNOT(wires=[2, 3])\n",
    "    qml.CNOT(wires=[3, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b2595f-2440-4ed0-ab9c-fee6d9aaea84",
   "metadata": {},
   "source": [
    "We also need a way to encode data inputs into the circuit, so that the measured output depends on the inputs. In this example, the inputs are bitstrings, which we encode into the state of the qubits using the BasisState function provided by PennyLane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d82b0f9-6df2-43c4-aa2e-4c1c9f835116",
   "metadata": {},
   "outputs": [],
   "source": [
    "def statepreparation(x):\n",
    "    qml.BasisState(x, wires=[0, 1, 2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e6c415-4726-42c6-b776-8cabff474fa5",
   "metadata": {},
   "source": [
    "Now we define the quantum node as a state preparation routine, followed by a repetition of the layer structure. Borrowing from machine learning, we call the parameters weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e9ee69-96e6-4a8a-93c0-ba6f313e2f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "@qml.qnode(dev)\n",
    "def circuit(weights, x):\n",
    "\n",
    "    statepreparation(x)\n",
    "\n",
    "    for W in weights:\n",
    "        layer(W)\n",
    "\n",
    "    return qml.expval(qml.PauliZ(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a49874-c554-43c7-89b8-eb23e083dd21",
   "metadata": {},
   "source": [
    "The quantum node takes the data as a keyword argument x (with the default value None). Keyword arguments of a quantum node are considered as fixed when calculating a gradient; they are never trained.\n",
    "\n",
    "If we want to add a “classical” bias parameter, the variational quantum classifier also needs some post-processing. We define the final model by a classical node that uses the first variable, and feeds the remainder into the quantum node. Before this, we reshape the list of remaining variables for easy use in the quantum node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547764c6-accb-4e21-b4d6-0008ab739661",
   "metadata": {},
   "outputs": [],
   "source": [
    "def variational_classifier(weights, bias, x):\n",
    "    return circuit(weights, x) + bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ac3665-99fe-4d30-bdf8-d75360417df5",
   "metadata": {},
   "source": [
    "## Cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab70bb9-e47a-4f28-87e5-e77ae371bc1f",
   "metadata": {},
   "source": [
    "In supervised learning, the cost function is usually the sum of a loss function and a regularizer. We use the standard square loss that measures the distance between target labels and model predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902c39ab-3374-4fbd-a712-9fc37cc004f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def square_loss(labels, predictions):\n",
    "    loss = 0\n",
    "    for l, p in zip(labels, predictions):\n",
    "        loss += (l - p) ** 2\n",
    "\n",
    "    loss /= len(labels)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e55d21b-3142-4bc1-b6c9-b9c00abef65f",
   "metadata": {},
   "source": [
    "To monitor how many inputs the current classifier predicted correctly, we also define the accuracy given target labels and model predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f000a86-f2f2-4d97-be08-8dfc08366e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(labels, predictions):\n",
    "\n",
    "    loss = 0\n",
    "    for l, p in zip(labels, predictions):\n",
    "        if abs(l - p) < 1e-5:\n",
    "            loss += 1\n",
    "    loss /= len(labels)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb5b61b-a50c-4bb5-8b24-d17f605f61e7",
   "metadata": {},
   "source": [
    "For learning tasks, the cost depends on the data - here the features and labels considered in the iteration of the optimization routine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce8d0b3-a20e-4b63-ab13-043d5e64b8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(weights, bias, X, Y):\n",
    "    predictions = [variational_classifier(weights, bias, x) for x in X]\n",
    "    return square_loss(Y, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1e4e11-9a77-4b7c-babd-d37e0d38f229",
   "metadata": {},
   "source": [
    "## Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d8402e-2878-42d4-8cc7-8498fc07c102",
   "metadata": {},
   "source": [
    "Let’s now load and preprocess some data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0298249c-46eb-4acd-a612-c6c531e77123",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt(\"data/parity.txt\")\n",
    "X = np.array(data[:, :-1], requires_grad=False)\n",
    "Y = np.array(data[:, -1], requires_grad=False)\n",
    "Y = Y * 2 - np.ones(len(Y))  # shift label from {0, 1} to {-1, 1}\n",
    "\n",
    "for i in range(5):\n",
    "    print(\"X = {}, Y = {: d}\".format(X[i], int(Y[i])))\n",
    "\n",
    "print(\"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c17911-7382-4487-b725-49d1669d896b",
   "metadata": {},
   "source": [
    "We initialize the variables randomly (but fix a seed for reproducibility). The first variable in the list is used as a bias, while the rest is fed into the gates of the variational circuit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02de89b-d8df-4533-a1c7-c7ff252389fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "num_qubits = 4\n",
    "num_layers = 2\n",
    "weights_init = 0.01 * np.random.randn(num_layers, num_qubits, 3, requires_grad=True)\n",
    "bias_init = np.array(0.0, requires_grad=True)\n",
    "\n",
    "print(weights_init, bias_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d988fa-be2d-499a-9d82-42792ddf3b4e",
   "metadata": {},
   "source": [
    "Next we create an optimizer and choose a batch size…\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549da3a6-5a61-4ea7-9819-347d09d908c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = NesterovMomentumOptimizer(0.5)\n",
    "batch_size = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f19277-1b60-4ad8-a655-0ec3490dd6e5",
   "metadata": {},
   "source": [
    "…and train the optimizer. We track the accuracy - the share of correctly classified data samples. For this we compute the outputs of the variational classifier and turn them into predictions in {−1,1} by taking the sign of the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c3265c-3d2a-4343-94a6-95760a114a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights, bias = weights_init, bias_init\n",
    "data = []\n",
    "for it in range(25):\n",
    "\n",
    "    # Update the weights by one optimizer step.\n",
    "    batch_index = np.random.randint(0, len(X), (batch_size,))\n",
    "    X_batch = X[batch_index]\n",
    "    Y_batch = Y[batch_index]\n",
    "    weights, bias, _, _ = opt.step(cost, weights, bias, X_batch, Y_batch)\n",
    "\n",
    "    # Compute accuracy.\n",
    "    predictions = [np.sign(variational_classifier(weights, bias, x)) for x in X]\n",
    "    acc = accuracy(Y, predictions)\n",
    "\n",
    "    data.append((it+1, cost(weights, bias, X, Y), acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37134df3-bf58-4e05-a943-29324bdd785e",
   "metadata": {},
   "source": [
    "Let's plot the accuracy as a function of the iteration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49446250-eed8-4976-a052-35e698f94924",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['figure.figsize'] = 12, 6.75\n",
    "plt.rcParams['font.size'] = 16\n",
    "             \n",
    "it, cost, acc = zip(*data)\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "color = 'tab:red'\n",
    "ax1.set_xlabel('Iteration')\n",
    "ax1.set_ylabel('Cost', color=color)\n",
    "ax1.plot(it, cost, color=color, marker='x')\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "color = 'tab:blue'\n",
    "ax2.set_ylabel('Accuracy', color=color)\n",
    "ax2.plot(it, acc, color=color, marker='o')\n",
    "ax2.tick_params(axis='y', labelcolor=color)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b04e24b-312e-481e-9261-4db24cc95efb",
   "metadata": {},
   "source": [
    "The accuracy should hit 1 after 5-10 iterations. Congratulations, you've used cuQuantum and lightning.gpu to train a variational classifier! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8613f52-119d-4814-abb1-5808142d955a",
   "metadata": {},
   "source": [
    "Obviously this is a simple example, but you can start experimenting with larger datasets, larger circuits, and more complex problems. Pennylane hosts a large number of demos here to get started: https://pennylane.ai/qml/demos_qml.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcdcc29e-a52e-45f2-9cfc-725b1c109c92",
   "metadata": {},
   "source": [
    "## Afternotes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802684cb-3954-4347-94b5-ce2aba724c17",
   "metadata": {},
   "source": [
    "In this tutorial we explored the cuQuantum-based lightning.gpu simulator now available in Pennylane. We ran a benchmark to see the acceleration compared to the fastest available CPU simulator, and then used lightning.gpu to train a simple variational classifier. \n",
    "\n",
    "We encourage you to continue exploring what can be done with lightning.gpu. Quantum machine learning is a nascent field, and there is tremendous opportunity for new research and discovery. \n",
    "\n",
    "For more on lightning.gpu see the [documentation](https://pennylane-lightning-gpu.readthedocs.io/en/latest/), as well as their [Github](https://github.com/PennyLaneAI/pennylane-lightning-gpu) repository.\n",
    "\n",
    "Please refer to the [documentation](https://docs.nvidia.com/cuda/cuquantum/python/index.html) and explore the [samples](https://github.com/NVIDIA/cuQuantum/tree/main/python/samples) on GitHub to learn more about cuQuantum.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
