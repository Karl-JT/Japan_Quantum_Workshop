{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi GPU simulations \n",
    "\n",
    "Below we will explore how CUDAQ can seamlessly utilize multiple GPUs and multiple QPUs in the future. \n",
    "\n",
    "1. Scale qubit count to access second and third GPU \n",
    "2. Distribute collection of x_train on multiple GPUs asynchronously\n",
    "3. Distribute collection of terms in a given hamiltonian\n",
    "4. Execute different kernels on different GPUs \n",
    "5. Scale achieved with multi-GPU tensor network simulations \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudaq\n",
    "from cudaq import spin\n",
    "import numpy as np\n",
    "\n",
    "cudaq.set_target('nvidia')\n",
    "# cudaq.set_target('nvidia-mgpu')\n",
    "# cudaq.set_target('qpp-cpu')\n",
    "# cudaq.set_target('nvidia-mqpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling qubit count to go beyond single GPU memory requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_qubits = 20\n",
    "n_samples = 1000\n",
    "h = spin.z(0) \n",
    "\n",
    "n_parameters = n_qubits*3\n",
    "parameters = np.random.default_rng(13).uniform(low=0, high=1, size = (n_samples,n_parameters))\n",
    "np.random.seed(1)\n",
    "\n",
    "\n",
    "kernel, params = cudaq.make_kernel(list)\n",
    "\n",
    "qubits = kernel.qalloc(n_qubits)\n",
    "qubits_list = list(range(n_qubits))\n",
    "\n",
    "for i in range(n_qubits):\n",
    "    kernel.rx(params[i], qubits[i])\n",
    "\n",
    "for i in range(n_qubits):\n",
    "    kernel.ry(params[i + n_qubits], qubits[i])\n",
    "\n",
    "for i in range(n_qubits):\n",
    "    kernel.rz(params[i + n_qubits*2], qubits[i])\n",
    "\n",
    "for q1, q2 in zip(qubits_list[0::2], qubits_list[1::2]):\n",
    "    kernel.cz(qubits[q1], qubits[q2])\n",
    "\n",
    "# exp_vals = cudaq.observe_n(kernel, h, parameters)\n",
    "\n",
    "exp_vals = [cudaq.observe(kernel, h, parameters[i]) for i in range(parameters.shape[0])]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graphs on MULTI GPU simulations scaling qubit counts for statevector and tensor network simulations \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Asynchronous data collection via batching x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(parameters.shape)\n",
    "\n",
    "xi = np.split(parameters, 4)\n",
    "\n",
    "print(len(xi))\n",
    "\n",
    "print(xi[0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asyncresults = []\n",
    "\n",
    "for i in range(len(xi)):\n",
    "    for j in range(xi[i].shape[0]):\n",
    "        asyncresults.append(cudaq.observe_async(kernel, h, xi[i][j,:], qpu_id = i))\n",
    "\n",
    "expvals = []\n",
    "for res in asyncresults:\n",
    "    expvals.append(res.get().expectation_z())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Asynchronous data collection via batching hamiltonian terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cudaq.set_qpu('cuquantum_mgpu')\n",
    "\n",
    "n_qubits = 10\n",
    "n_samples = 1000\n",
    "\n",
    "hamiltonian = 5.907 - 2.1433 * spin.x(0) * spin.x(1) - 2.1433 * spin.y(\n",
    "    0) * spin.y(1) + .21829 * spin.z(0) - 6.125 * spin.z(1)\n",
    "\n",
    "n_parameters = n_qubits*3\n",
    "parameters = np.random.default_rng(13).uniform(low=0, high=1, size = (n_samples,n_parameters))\n",
    "np.random.seed(1)\n",
    "\n",
    "\n",
    "kernel, params = cudaq.make_kernel(list)\n",
    "\n",
    "qubits = kernel.qalloc(n_qubits)\n",
    "qubits_list = list(range(n_qubits))\n",
    "\n",
    "for i in range(n_qubits):\n",
    "    kernel.rx(params[i], qubits[i])\n",
    "\n",
    "for i in range(n_qubits):\n",
    "    kernel.ry(params[i + n_qubits], qubits[i])\n",
    "\n",
    "for i in range(n_qubits):\n",
    "    kernel.rz(params[i + n_qubits*2], qubits[i])\n",
    "\n",
    "for q1, q2 in zip(qubits_list[0::2], qubits_list[1::2]):\n",
    "    kernel.cz(qubits[q1], qubits[q2])\n",
    "\n",
    "# exp_vals = cudaq.observe_n(kernel, h, parameters)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different kernels being executed at the same time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cudaq.set_target('nvidia-mgpu')\n",
    "\n",
    "n_qubits = 10\n",
    "n_samples = 500\n",
    "h = spin.z(0) \n",
    "\n",
    "n_parameters = n_qubits\n",
    "parameters = np.random.default_rng(13).uniform(low=0, high=1, size = (n_samples,n_parameters))\n",
    "np.random.seed(1)\n",
    "\n",
    "###################################################\n",
    "\n",
    "kernel1, params = cudaq.make_kernel(list)\n",
    "\n",
    "qubits = kernel1.qalloc(n_qubits)\n",
    "\n",
    "for i in range(n_qubits):\n",
    "    kernel1.rx(params[i], qubits[i])\n",
    "\n",
    "###################################################\n",
    "\n",
    "kernel2, params = cudaq.make_kernel(list)\n",
    "\n",
    "qubits = kernel2.qalloc(n_qubits)\n",
    "\n",
    "for i in range(n_qubits):\n",
    "    kernel2.rx(params[i], qubits[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asyncresults = []\n",
    "\n",
    "for i in range(len(xi)):\n",
    "    for j in range(xi[i].shape[0]):\n",
    "        asyncresults.append(cudaq.observe_async(kernel, h, xi[i][j,:], qpu_id = i))\n",
    "\n",
    "expvals = []\n",
    "for res in asyncresults:\n",
    "    expvals.append(res.get().expectation_z())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "exp_vals1 = [cudaq.observe_async(kernel1, h, parameters[i], qpu_id = 0) for i in range(parameters.shape[0])]\n",
    "\n",
    "exp_vals2 = [cudaq.observe_async(kernel2, h, parameters[i], qpu_id = 1) for i in range(parameters.shape[0])]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unparalleled scale with tensor networks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(cudaq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cudaq.set_target('tensornet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Future syntax: simultaneous QPU-GPU workflows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simultaneous gpu qpu execution \n",
    "\n",
    "cudaq.sample_n_async(kernel, h, x_train, params, qpu_id = 'Rigetti-Aspen-X')\n",
    "\n",
    "\n",
    "cudaq.sample_n_async(kernel_clifford_approximation, h, x_train, params, qpu_id = 'Clifford-Simulator')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
